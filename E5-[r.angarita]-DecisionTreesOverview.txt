VISIÓN GENERAL DE LOS ARBOLES DE DECISIÓN
Los árboles de decisión son métodos de extracción de datos para predecir una variable de respuesta única basada en múltiples variables de predicción. Si la variable de respuesta es categórica o discreta, el problema de la minería de datos es un problema de clasificación, mientras que la respuesta es continua, el problema es un tipo de problema de regresión. Los árboles de decisión son generalmente aplicables en ambas situaciones.
Los algoritmos de crecimiento de árboles tienen pasos similares, a partir de todas las observaciones en un nodo raíz, se selecciona una variable predictiva para dividir el conjunto de datos en dos o más nodos o ramas. La forma de la división depende del tipo de predictor y de los detalles específicos del algoritmo. Si el predictor es categórico, tomando valores discretos, por ejemplo, la división puede consistir en dos o más subconjuntos adecuados. Si el predictor es continuo, una división constará de dos o más intervalos. El proceso de división se repite para cada nodo secundario y continúa de tal manera hasta que se presenta una de las varias posibles condiciones de parada. El resultado del algoritmo del árbol de decisión es una estructura de árbol con una raíz y un cierto número de ramas (o nodos). Cada rama define un subconjunto o partición de los datos y, condicional a ese subconjunto de datos, un valor predicho para la variable de respuesta. Un recorrido de una rama del árbol conduce a una predicción o decisión sobre la variable de respuesta. Para predecir una nueva observación fuera de la muestra, encontramos el nodo terminal al que pertenece la observación al atravesar el árbol y encontrar el subconjunto de datos (rama) que contiene la observación.
En otras palabras, es una herramienta de apoyo a la decisión que utiliza un gráfico o modelo de decisiones en forma de árbol y sus posibles consecuencias, como los resultados de eventos al azar, los costos de recursos y la utilidad.
